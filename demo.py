import streamlit as st
import cv2
import numpy as np
import onnxruntime as ort
from PIL import Image
import torchvision.transforms as transforms

st.set_page_config(page_title="Facial Expression Recognition", layout="centered")
st.title("üòÉ Real-time Facial Expression Recognition")
st.markdown("Upload a face image (48x48 grayscale or larger) or use your webcam.")

# Nh√£n c·∫£m x√∫c (ph·∫£i ƒë√∫ng th·ª© t·ª±)
# class_names = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']
class_names = ['Happy', 'Sleepy', 'Surprise']

# Load ONNX model
session = ort.InferenceSession("models/emotion_cnn.onnx", providers=['CPUExecutionProvider'])

# H√†m ti·ªÅn x·ª≠ l√Ω
def preprocess_image(img: Image.Image):
    transform = transforms.Compose([
        transforms.Grayscale(),
        transforms.Resize((48, 48)),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5])
    ])
    tensor = transform(img).unsqueeze(0).numpy()  # shape: (1, 1, 48, 48)
    return tensor

# H√†m d·ª± ƒëo√°n
def predict_emotion(img: Image.Image):
    input_tensor = preprocess_image(img)
    outputs = session.run(None, {"input": input_tensor})
    scores = outputs[0][0]
    predicted = np.argmax(scores)
    confidence = float(np.exp(scores[predicted]) / np.sum(np.exp(scores)))
    return class_names[predicted], confidence

# Giao di·ªán
uploaded_file = st.file_uploader("üìÅ Upload ·∫£nh khu√¥n m·∫∑t", type=["png", "jpg", "jpeg"])
if uploaded_file is not None:
    img = Image.open(uploaded_file).convert("RGB")
    st.image(img, caption="·∫¢nh ƒë√£ t·∫£i l√™n", width=200)
    emotion, conf = predict_emotion(img)
    st.success(f"**Emotion:** {emotion} ({conf*100:.2f}%)")

# Webcam
if st.button("üì∑ D√πng webcam"):
    st.warning("‚ö†Ô∏è Vui l√≤ng ch·∫°y file local v√¨ Streamlit cloud kh√¥ng h·ªó tr·ª£ webcam.")
